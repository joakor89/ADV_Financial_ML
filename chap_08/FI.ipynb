{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "335cc01d-ca33-4caa-8a0c-0502cfe2b6ce",
   "metadata": {},
   "source": [
    "# Feature Importance\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af9f97ab-eb66-488c-b996-7a2d741d5862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomness\n",
    "import random\n",
    "\n",
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "from pandas import Timestamp\n",
    "\n",
    "# Data Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "%matplotlib inline\n",
    "\n",
    "# Date & Time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Typing\n",
    "from typing import Tuple, List, Dict, Union, Optional, Any, Generator\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, plot_roc_curve\n",
    "\n",
    "# Scientific Statistical Python\n",
    "from scipy.stats import jarque_bera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1869990-13d1-4072-9152-682d42a069d7",
   "metadata": {},
   "source": [
    "## Feature Importance with Substitution Effects\n",
    "\n",
    "### Mean Decrease Impurity (MDI)\n",
    "#### MDI Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b2bfdf-107f-4c07-9696-e49be37141b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_imp_MDI(fit: Any, featNames: np.ndarray) -> pd.DataFrame:\n",
    "    df0 = {i: tree.feature_importances_ for i, tree in enumerate(fit.estimators_)}\n",
    "    df0 = pd.DataFrame.from_dict(df0, orient='index')\n",
    "    df0.columns = featNames\n",
    "    df0 = df0.replace(0, np.nan)    # because max_features=1\n",
    "    imp = pd.concat({'mean': df0.mean(), 'std': df0.std() * df0.shape[0] ** (-0.5)}, axis=1)\n",
    "    imp /= imp['mean'].sum()\n",
    "    return imp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bbdb6c-82dc-4bf4-9cc2-e382fcc4284e",
   "metadata": {},
   "source": [
    "### Mean Decrease Accuracy\n",
    "#### MDA Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f2ce91d-8748-4d64-adc1-9d0022df70d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_imp_MDA(\n",
    "    clf: Any, X: pd.DataFrame, y: pd.Series, cv: int, sample_weight: pd.Series,\n",
    "    t1: pd.Series, pctEmbargo: float, scoring: str = 'neg_log_loss') -> Tuple[pd.DataFrame, float]:\n",
    "\n",
    "    if scoring not in ['neg_log_loss', 'accuracy']:\n",
    "        raise Exception('wrong scoring method.')\n",
    "    cvGen = PurgedKFold(n_splits=cv, t1=t1, pctEmbargo=pctEmbargo)    # purged cv\n",
    "    scr0, scr1 = pd.Series(), pd.DataFrame(columns=X.columns, dtype=object)\n",
    "    \n",
    "    for i, (train, test) in enumerate(cvGen.split(X=X)):\n",
    "        X0, y0, w0 = X.iloc[train, :], y.iloc[train], sample_weight.iloc[train]\n",
    "        X1, y1, w1 = X.iloc[test, :], y.iloc[test], sample_weight.iloc[test]\n",
    "        fit = clf.fit(X=X0, y=y0, sample_weight=w0.values)\n",
    "        if scoring == 'neg_log_loss':\n",
    "            prob = fit.predict_proba(X1)\n",
    "            scr0.loc[i] = -log_loss(y1, prob, sample_weight=w1.values, labels=clf.classes_)\n",
    "        else:\n",
    "            pred = fit.predict(X1)\n",
    "            scr0.loc[i] = accuracy_score(y1, pred, sample_weight=w1.values)\n",
    "        for j in X.columns:\n",
    "            X1_ = X1.copy(deep=True)\n",
    "            np.random.shuffle(X1_[j].values)    # permutation of a single column\n",
    "            if scoring == 'neg_log_loss':\n",
    "                prob = fit.predict_proba(X1_)\n",
    "                scr1.loc[i, j] = -log_loss(y1, prob, sample_weight=w1.values, labels=clf.classes_)\n",
    "            else:\n",
    "                pred = fit.predict(X1_)\n",
    "                scr1.loc[i, j] = accuracy_score(y1, pred, sample_weight=w1.values)\n",
    "    imp = (-scr1).add(scr0, axis=0)\n",
    "    if scoring == 'neg_log_loss':\n",
    "        imp = imp / -scr1\n",
    "    else:\n",
    "        imp = imp / (1.0 - scr1)\n",
    "    imp = pd.concat({'mean': imp.mean(), 'std': imp.std() * imp.shape[0] ** (-0.5)}, axis=1)\n",
    "    return imp, scr0.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c394170-eebd-47fc-9e51-1e6ee065a0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
