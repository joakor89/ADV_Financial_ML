{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51119750-e230-4396-9b3a-674f16c391cf",
   "metadata": {},
   "source": [
    "# Machine Learning Asset Allocation\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f44a730-aa8a-49e7-ae27-47053cffa839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomness\n",
    "import random\n",
    "\n",
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "from pandas import Timestamp\n",
    "\n",
    "# Data Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "%matplotlib inline\n",
    "\n",
    "# Date & Time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Typing\n",
    "from typing import Tuple, List, Dict, Union, Optional, Any, Generator\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection._split import _BaseKFold\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, log_loss\n",
    "\n",
    "# Scientific Statistical Python\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.stats import jarque_bera\n",
    "from scipy.stats import rv_continuous, kstest, norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb1eae5-8520-4d96-91ce-d7a5d8a6aad7",
   "metadata": {},
   "source": [
    "#### Inverse Invariance Portafolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1ab0e77-db31-4b14-a37a-3f3792535465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ivp(cov: np.ndarray, **kargs) -> np.ndarray:\n",
    "    ivp = 1.0 / np.diag(cov)\n",
    "    ivp /= ivp.sum()\n",
    "    return ivp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a092f7df-5c3c-42ba-b972-fb289ca7df5c",
   "metadata": {},
   "source": [
    "#### Variance per Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df07d3bf-2054-4759-adcc-769c443455a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_var(cov: np.ndarray, cItems: np.ndarray) -> float:\n",
    "    cov_ = cov.loc[cItems, cItems]    # matrix slice\n",
    "    w_ = get_ivp(cov_).reshape(-1, 1)\n",
    "    cVar = np.dot(np.dot(w_.T, cov_), w_)[0, 0]\n",
    "    return cVar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f01b5cd-23b5-4856-93fd-aae749e0cdde",
   "metadata": {},
   "source": [
    "#### Quasi-Diagonalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "655d6069-15aa-4a35-8895-2f24838ddc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quasi_diag(link: np.ndarray) -> list:\n",
    "    link = link.astype(int)\n",
    "    sortIx = pd.Series([link[-1, 0], link[-1, 1]])\n",
    "    numItems = link[-1, 3]    \n",
    "    while sortIx.max() >= numItems:\n",
    "        sortIx.index = range(0, sortIx.shape[0] * 2, 2)    \n",
    "        df0 = sortIx[sortIx >= numItems]    \n",
    "        i = df0.index\n",
    "        j = df0.values - numItems\n",
    "        sortIx[i] = link[j, 0]    \n",
    "        df0 = pd.Series(link[j, 1], index=i+1)\n",
    "        sortIx = sortIx.append(df0)    # item 2\n",
    "        sortIx = sortIx.sort_index()    # re-sort\n",
    "        sortIx.index = range(sortIx.shape[0])    \n",
    "    lst =  sortIx.tolist()\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a96eac-67aa-4103-aee3-5b5f43249203",
   "metadata": {},
   "source": [
    "#### Hierarchical Risk Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93a7d6c0-94d5-462e-8f7e-3b81a2e45eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rec_bipart(cov: np.ndarray, sortIx: list) -> pd.Series:\n",
    "    w = pd.Series([1] * len(sortIx), index=sortIx)\n",
    "    cItems = [sortIx]    \n",
    "    while len(cItems) > 0:\n",
    "        cItems = [i[int(j): int(k)] for i in cItems\n",
    "                  for j, k in ((0, len(i) / 2), (len(i) / 2, len(i))) if len(i) > 1]    \n",
    "        for i in range(0, len(cItems), 2):    \n",
    "            cItems0 = cItems[i]    \n",
    "            cItems1 = cItems[i+1]    \n",
    "            cVar0 = get_cluster_var(cov, cItems0)\n",
    "            cVar1 = get_cluster_var(cov, cItems1)\n",
    "            alpha = 1 - cVar0 / (cVar0 + cVar1)\n",
    "            w[cItems0] *= alpha    \n",
    "            w[cItems1] *= 1 - alpha    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51815622-6fe5-4735-94a8-acbe6ca82380",
   "metadata": {},
   "source": [
    "#### Distance Matrix Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f449c3bb-1c22-4a63-8234-d82dce0c78d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correl_dist(corr: np.ndarray) -> np.ndarray:\n",
    "    dist = ((1 - corr) / 2.0) ** 0.5    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6476f05d-7c9c-4cbc-afe1-9234dabccfd6",
   "metadata": {},
   "source": [
    "#### Correlation Matrix Heat Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92283240-c0f7-4ed0-a4ee-4568e3ef04bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_matrix(corr: np.ndarray, labels: list = None, size: tuple = (9, 9)) -> None:\n",
    "    fig, ax = plt.subplots(figsize=size)\n",
    "    if labels is None:\n",
    "        labels = []\n",
    "    ax = sns.heatmap(corr)\n",
    "    ax.set_yticks(np.arange(0.5, corr.shape[0] + 0.5), list(labels))\n",
    "    ax.set_xticks(np.arange(0.5, corr.shape[0] + 0.5), list(labels))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5ad70e-e287-402e-ad0b-15028043ca35",
   "metadata": {},
   "source": [
    "#### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5de75030-39c9-4c77-93fa-202901c5df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(nObs: int, size0: int, size1: int, sigma1: float) -> Tuple[pd.DataFrame, list]:\n",
    "    np.random.seed(seed=42)\n",
    "    random.seed(42)\n",
    "    x = np.random.normal(0, 1, size=(nObs, size0))    \n",
    "    cols = [random.randint(0, size0 - 1) for i in range(size1)]\n",
    "    y = x[:, cols] + np.random.normal(0, sigma1, size=(nObs, len(cols)))\n",
    "    x = np.append(x, y, axis=1)\n",
    "    x = pd.DataFrame(x, columns=range(1, x.shape[1] + 1))\n",
    "    return x, cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799792db-d2ac-42ab-8e3a-ab23d72b8075",
   "metadata": {},
   "source": [
    "#### Running Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e45d0f83-c5d9-490f-be92-5926a99edc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation() -> None:\n",
    "    nObs, size0, size1, sigma1 = 10000, 5, 5, 0.25\n",
    "    x, cols = generate_data(nObs, size0, size1, sigma1)\n",
    "    print([(j + 1, size0 + i) for i, j in enumerate(cols, 1)])\n",
    "    cov, corr = x.cov(), x.corr()\n",
    "    plot_corr_matrix(corr, labels=corr.columns, size=(8, 6.5))\n",
    "    dist = correl_dist(corr)\n",
    "    link = sch.linkage(dist, 'single')\n",
    "    sortIx = get_quasi_diag(link)\n",
    "    sortIx = corr.index[sortIx].tolist()    \n",
    "    df0 = corr.loc[sortIx, sortIx]    \n",
    "    plot_corr_matrix(df0, labels=df0.columns, size=(8, 6.5))\n",
    "    hrp = get_rec_bipart(cov, sortIx)\n",
    "    print(hrp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62054de7-15a4-4a4a-a94d-4c1f0099cd94",
   "metadata": {},
   "source": [
    "#### Random Shocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45e45826-3fe7-43f0-bef1-d7e2e34a8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_mc(nObs: int, sLength: int, size0: int, size1: int, mu0: float, sigma0: float, sigma1F: float) -> Tuple[np.ndarray, list]:\n",
    "    x = np.random.normal(mu0, sigma0, size=(nObs, size0))\n",
    "    cols = [random.randint(0, size0 - 1) for i in range(size1)]\n",
    "    y = x[:, cols] + np.random.normal(0, sigma0 * sigma1F, size=(nObs, len(cols)))\n",
    "    x = np.append(x, y, axis=1)\n",
    "    point = np.random.randint(sLength, nObs - 1, size=2)\n",
    "    x[np.ix_(point, [cols[0], size0])] = np.array([[-0.5, -0.5], [2, 2]])\n",
    "    point = np.random.randint(sLength, nObs - 1, size=2)\n",
    "    x[point, cols[-1]] = np.array([-0.5, 2])\n",
    "    return x, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7f5168-4c3f-47e6-8c82-653d33de2582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
